{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import strax\n",
    "import numpy as np\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import strax.ecosystem as es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'peak_details': <strax.ecosystem.PeakDetails at 0x4def278>,\n",
       " 'peak_widths': <strax.ecosystem.PeakWidths at 0x3a12a20>,\n",
       " 'raw_records': <strax.ecosystem.RawRecords at 0x7c90dd8>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.PROVIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = es.PROVIDES['peak_widths'].task_graph('some_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('PeakDetails',\n",
       "  '0.0.1'): (<bound method StraxExtension._compute of <strax.ecosystem.PeakDetails object at 0x0000000004DEF278>>, 'some_run', ('RawRecords',\n",
       "   '0.0.1')),\n",
       " ('PeakWidths',\n",
       "  '0.1'): (<bound method StraxExtension._compute of <strax.ecosystem.PeakWidths object at 0x0000000003A12A20>>, 'some_run', ('PeakDetails',\n",
       "   '0.0.1')),\n",
       " ('RawRecords',\n",
       "  '0.0.1'): (<bound method StraxExtension._compute of <strax.ecosystem.RawRecords object at 0x0000000007C90DD8>>, 'some_run')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cached_file(key, lin):\n",
    "    if key == ('PeakDetails', '0.0.1'):\n",
    "        return 'some_records_file.zstd'\n",
    "    \n",
    "def load_from_cache(filename):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Produce a new task graph with computes replaced by load from cache\n",
    "# at as high a level as possible\n",
    "##\n",
    "self_key = ('PeakWidths', '0.1')\n",
    "\n",
    "# Map of direct dependencies for each task\n",
    "direct_deps_of = dask.optimize.cull(tg, self_key)[1]\n",
    "\n",
    "tg_new = {}\n",
    "stack = [self_key]\n",
    "while len(stack):\n",
    "    key = stack.pop()\n",
    "    if key in tg_new:\n",
    "        # We're already on the new task graph\n",
    "        continue\n",
    "        \n",
    "    # Get full lineage of key\n",
    "    # Do we have this on ice?\n",
    "    lin = lineage(tg, key)\n",
    "    filename = find_cached_file(key, lin)\n",
    "    if filename:\n",
    "        # YES, add a *load_from_cache* to the new task graph\n",
    "        tg_new[key] = (load_from_cache, filename)\n",
    "        pass\n",
    "    else:    \n",
    "        # NO, the original *compute* goes on the task graph\n",
    "        # Put its dependencies on the stack.\n",
    "        tg_new[key] = tg[key]\n",
    "        stack.extend(direct_deps_of[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('PeakDetails', '0.0.1'): (<function __main__.load_from_cache>,\n",
       "  'some_records_file.zstd'),\n",
       " ('PeakWidths',\n",
       "  '0.1'): (<bound method StraxExtension._compute of <strax.ecosystem.PeakWidths object at 0x0000000003A12A20>>, 'some_run', ('PeakDetails',\n",
       "   '0.0.1'))}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('PeakDetails', '0.0.1'), ('RawRecords', '0.0.1')}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute full lineage set for each task\n",
    "def lineage(tg, k):\n",
    "    ks = set(dask.optimize.cull(tg, k)[0].keys())\n",
    "    ks.remove(k)\n",
    "    return ks\n",
    "\n",
    "lineage(tg, ('PeakWidths', '0.1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PeakWidths', '0.1') {('PeakDetails', '0.0.1'), ('RawRecords', '0.0.1')}\n",
      "('PeakDetails', '0.0.1') {('RawRecords', '0.0.1')}\n",
      "('RawRecords', '0.0.1') set()\n"
     ]
    }
   ],
   "source": [
    "# TODO: PROVIDING algorithm must be in key!\n",
    "new_tg = dict()\n",
    "for k in list(reversed(dask.core.toposort(tg))):\n",
    "    dep_keys = set(dask.optimize.cull(tg, k)[0].keys())\n",
    "    dep_keys.remove(k)\n",
    "    print(k, dep_keys)\n",
    "    # Look up in db\n",
    "    # If exists, put load from cache in new task graph\n",
    "    # If not exists, keep compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kset.remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Hash these, look them up.\n",
    "For all available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PeakWidths.compute of <strax.ecosystem.PeakWidths object at 0x0000000007A04D68>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.PROVIDES['peak_widths'].compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_compute-2a4dc50f-602e-4396-b115-4a06ff7a7418': (<bound method StraxExtension._compute of <strax.ecosystem.ProcessedData object at 0x0000000007A10080>>,\n",
       "  'some_run',\n",
       "  '_compute-866adb99-1224-48df-99c1-6c87cfa2e5a2'),\n",
       " '_compute-866adb99-1224-48df-99c1-6c87cfa2e5a2': (<bound method StraxExtension._compute of <strax.ecosystem.RawRecords object at 0x0000000007C9CC88>>,\n",
       "  'some_run'),\n",
       " '_compute-fe45645c-25c4-47ee-bd88-ae02d2e07b84': (<bound method StraxExtension._compute of <strax.ecosystem.PeakWidths object at 0x0000000007A04D68>>,\n",
       "  'some_run',\n",
       "  '_compute-2a4dc50f-602e-4396-b115-4a06ff7a7418')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.dot import dot_graph\n",
    "\n",
    "dict(tg.dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
