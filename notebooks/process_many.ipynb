{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100   # Hm, not ideal. Shorten comments?\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from strax import *\n",
    "chio = io_chunked\n",
    "\n",
    "# ADC->PE conversions for XENON1T\n",
    "to_pe = 1e-3 * np.array([7.05, 0.0, 0.0, 8.09, 4.38, 7.87, 3.58, 7.5, 7.44, 4.82, 7.07, 5.79,  0.0, 5.55, 7.95, 7.02, 6.39, 8.1, 7.15, 7.43, 7.15, 11.4, 3.97, 7.28,  5.41, 7.4, 0.0, 0.0, 7.04, 7.27, 4.22, 16.79, 4.14, 7.04, 0.0, 5.38,  7.39, 7.02, 4.53, 5.17, 7.13, 5.48, 4.6, 7.33, 6.14, 6.52, 7.59,  4.76, 7.56, 7.54, 4.57, 4.6, 7.12, 8.0, 4.7, 8.68, 3.74, 4.97, 10.36,  7.53, 6.02, 12.45, 0.0, 4.49, 4.82, 0.0, 8.13, 7.27, 3.55, 5.65,  4.55, 8.64, 7.97, 0.0, 3.57, 3.69, 5.87, 5.12, 9.8, 0.0, 5.08, 4.09,  3.87, 8.17, 6.73, 9.03, 0.0, 6.93, 0.0, 6.52, 7.39, 0.0, 4.92, 7.48,  5.82, 4.05, 3.9, 5.77, 8.14, 7.62, 7.61, 5.55, 0.0, 7.12, 5.02, 4.57,  4.46, 7.44, 3.57, 7.58, 7.16, 7.33, 7.69, 6.03, 5.87, 9.64, 4.68,  7.88, 0.0, 10.84, 7.0, 3.62, 7.5, 7.45, 7.69, 7.69, 3.49, 3.61, 7.44,  6.38, 0.0, 5.1, 3.72, 5.22, 0.0, 0.0, 4.43, 0.0, 3.87, 0.0, 3.6,  5.35, 8.4, 5.1, 6.45, 5.07, 4.28, 3.5, 0.0, 7.28, 0.0, 4.25, 0.0,  4.72, 6.26, 7.28, 5.34, 7.55, 3.85, 5.54, 7.5, 7.31, 0.0, 7.76, 7.57,  6.66, 7.29, 0.0, 7.59, 3.8, 3.58, 5.21, 4.29, 7.36, 7.76, 4.0, 6.23,  5.86, 0.0, 7.34, 3.58, 3.57, 5.26, 0.0, 7.67, 4.05, 4.3, 4.21, 7.59,  7.59, 0.0, 6.41, 4.86, 3.73, 5.09, 7.59, 7.64, 7.7, 0.0, 5.25, 8.0,  5.32, 7.91, 0.0, 4.41, 11.82, 0.0, 4.51, 7.05, 8.63, 5.12, 4.45,  4.03, 0.0, 0.0, 3.54, 4.18, 9.5, 3.64, 3.67, 7.28, 3.59, 5.03, 3.6,  5.4, 7.18, 3.73, 6.21, 6.47, 3.7, 7.69, 4.58, 7.46, 6.74, 0.0, 3.66,  7.49, 7.55, 3.64, 0.0, 7.34, 4.06, 3.74, 3.97, 0.0, 4.29, 4.96, 3.77,  8.57, 8.57, 8.57, 8.57, 8.57, 8.57, 214.29, 171.43, 171.43, 171.43,  171.43, 171.43])\n",
    "data_dir = os.path.abspath('./180219_2005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This PMT is mad and oscillates terribly\n",
    "to_pe[87] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add first_time to records chunk metadata. Should have been done when writing the files...\n",
    "# for fn in tqdm(chio.chunk_files(data_dir + '/records'),\n",
    "#                desc='Adding first_time info'):\n",
    "#     d, md = strax.load(fn, with_meta=True)\n",
    "#     md['first_time'] = int(d['time'][0])   # Without int, json complains\n",
    "#     strax.save_metadata(fn, **md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class ReducedRecords(StraxPlugin):\n",
    "    data_kind = 'records'\n",
    "    compressor = 'zstd'\n",
    "    dtype = record_dtype()\n",
    "    \n",
    "    seen_bytes = 0\n",
    "    \n",
    "    def compute(self, records):\n",
    "        r = records\n",
    "        self.seen_bytes += r.nbytes\n",
    "        integrate(r)\n",
    "        r = exclude_tails(r, to_pe)\n",
    "        return r\n",
    "    \n",
    "pl = ReducedRecords()\n",
    "pl.save(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class Peaks(StraxPlugin):\n",
    "    data_kind = 'peaks'\n",
    "    dtype = peak_dtype(n_channels=len(to_pe))\n",
    "    \n",
    "    def compute(self, reduced_records):\n",
    "        r = reduced_records\n",
    "        \n",
    "        hits = find_hits(r)\n",
    "        # strax.cut_outside_hits(r, hits)    # Was already done on conversion\n",
    "\n",
    "        peaks = find_peaks(hits, to_pe, \n",
    "                                 result_dtype=self.dtype)\n",
    "        sum_waveform(peaks, r, to_pe)\n",
    "        \n",
    "        peaks = split_peaks(peaks, r, to_pe)\n",
    "        \n",
    "        compute_widths(peaks)\n",
    "        return peaks\n",
    "    \n",
    "Peaks().save(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info('peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce peak info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class PeakBasics(StraxPlugin):\n",
    "    dtype = [\n",
    "        (('Peak integral in PE',\n",
    "            'area'), np.float32),\n",
    "        (('Number of PMTs contributing to the peak',\n",
    "            'n_channels'), np.int16),\n",
    "        (('PMT number which contributes the most PE',\n",
    "            'max_pmt'), np.int16),\n",
    "        (('Start time of the peak (ns since unix epoch)',\n",
    "            'time'), np.int64),\n",
    "        (('End time of the peak (ns since unix epoch)',\n",
    "            'endtime'), np.int64),\n",
    "        (('Width (in ns) of the central 50% area of the peak',\n",
    "            'range_50p_area'), np.float32),\n",
    "        (('Fraction of area seen by the top array',\n",
    "            'area_fraction_top'), np.float32),\n",
    "    ]\n",
    "\n",
    "    def compute(self, peaks):\n",
    "        p = peaks\n",
    "        r = np.zeros(len(p), self.dtype)\n",
    "        r['area'] = p['area']\n",
    "        r['n_channels'] = (p['area_per_channel'] > 0).sum(axis=1)\n",
    "        r['range_50p_area'] = p['width'][:,5]\n",
    "        r['max_pmt'] = np.argmax(p['area_per_channel'], axis=1)\n",
    "        r['time'] = p['time']\n",
    "        r['endtime'] = p['time'] + p['dt'] * p['length']\n",
    "\n",
    "        # TODO: get n_top_pmts from some config...\n",
    "        area_top = (p['area_per_channel'][:,:127] \n",
    "                    * to_pe[:127].reshape(1, -1)\n",
    "                   ).sum(axis=1)\n",
    "        r['area_fraction_top'] = area_top/p['area']\n",
    "        return r\n",
    "\n",
    "PeakBasics().save(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info('peak_basics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chio.slurp_df(data_dir + '/peak_basics')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes about 30x less memory than the raw peaks (with waveforms, area_per_channel, etc). A substantial reduction, but not enough to forego chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multihist import Histdd\n",
    "d = df\n",
    "mh = Histdd(d['area'], d['range_50p_area'],\n",
    "            bins=(np.logspace(0, 7, 100),\n",
    "                  np.logspace(1, 4, 100)))\n",
    "mh.plot(log_scale=True)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df[df['n_channels'] > 3]\n",
    "plt.scatter(d['area'], \n",
    "            d['range_50p_area'],\n",
    "            c=d['area_fraction_top'], \n",
    "            s=0.1,\n",
    "            cmap=plt.cm.rainbow, vmin=0, vmax=1)\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.colorbar(label='Area fraction top')\n",
    "plt.xlabel(\"Area (pe)\")\n",
    "plt.ylabel(\"Width (50% area, ns)\")\n",
    "plt.gca().patch.set_facecolor('black')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(1, 5e6)\n",
    "plt.ylim(10, 2e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class PeakClassification(StraxPlugin):\n",
    "    dtype = [\n",
    "        (('Classification of the peak.', \n",
    "            'type'), np.int8)\n",
    "    ]\n",
    "    \n",
    "    def compute(self, peak_basics):\n",
    "        p = peak_basics\n",
    "        r = np.zeros(len(p), dtype=self.dtype)\n",
    "        \n",
    "        is_s1 = p['area'] > 100\n",
    "        is_s1 &= p['range_50p_area'] < 150\n",
    "        r['type'][is_s1] = 1\n",
    "        \n",
    "        is_s2 = p['area'] > 1e4\n",
    "        is_s2 &= p['range_50p_area'] > 200\n",
    "        r['type'][is_s2] = 2\n",
    "        \n",
    "        return r\n",
    "\n",
    "PeakClassification().save(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class PeakInfo(MergePlugin):\n",
    "    depends_on = ('peak_basics', 'peak_classification')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = PeakInfo().process_and_slurp(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info('peak_info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class Events(StraxPlugin):\n",
    "    data_kind = 'events'\n",
    "    dtype = [\n",
    "        (('Event number in this dataset',\n",
    "              'event_number'), np.int64),\n",
    "        (('Event start time in ns since the unix epoch',\n",
    "              'time'), np.int64),\n",
    "        (('Event end time in ns since the unix epoch',\n",
    "              'endtime'), np.int64),\n",
    "    ]\n",
    "    \n",
    "    # Uh oh, state... must force sequential when we start doing multiprocessing\n",
    "    events_seen = 0\n",
    "    \n",
    "    def compute(self, peak_basics):\n",
    "        left_ext = int(1e6)\n",
    "        right_ext = int(1e6)\n",
    "        large_peaks = peak_basics[peak_basics['area'] > 1e5]\n",
    "        \n",
    "        # TODO: this can be done much faster\n",
    "        event_ranges = []\n",
    "        split_indices = np.where(np.diff(large_peaks['time']) > left_ext + right_ext)[0] + 1\n",
    "        for ps in np.split(large_peaks, split_indices):\n",
    "            start = ps[0]['time'] - left_ext\n",
    "            stop = ps[-1]['time'] + right_ext\n",
    "            event_ranges.append((start, stop))\n",
    "        event_ranges = np.array(event_ranges)\n",
    "        self.events_seen += len(event_ranges)\n",
    "\n",
    "        result = np.zeros(len(event_ranges), self.dtype)\n",
    "        result['time'], result['endtime'] = event_ranges.T\n",
    "        result['event_number'] = np.arange(len(event_ranges)) + self.events_seen\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Events().save(data_dir)\n",
    "events = Events().process_and_slurp(data_dir)\n",
    "\n",
    "# Events do not overlap\n",
    "assert np.min(events['time'][1:] - events['endtime'][:-1]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info('events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class EventBasics(LoopPlugin):\n",
    "    depends_on = ('events', 'peak_basics', 'peak_classification')\n",
    "    dtype = [(('Number of peaks in the event',\n",
    "                   'n_peaks'), np.int32),\n",
    "             \n",
    "             (('Main S1 peak index',\n",
    "                   's1_index'), np.int32),\n",
    "             (('Main S1 area (PE)',\n",
    "                   's2_area'), np.int32),\n",
    "             (('Main S1 area fraction top',\n",
    "                   's1_area_fraction_top'), np.float32),\n",
    "             (('Main S1 width (ns, 50% area)',\n",
    "                   's1_range_50p_area'), np.float32),\n",
    "             \n",
    "             (('Main S2 peak index',\n",
    "                   's2_index'), np.int32),\n",
    "             (('Main S2 area (PE)',\n",
    "                   's1_area'), np.int32),\n",
    "             (('Main S2 area fraction top',\n",
    "                   's2_area_fraction_top'), np.float32),\n",
    "             (('Main S2 width (ns, 50% area)',\n",
    "                   's2_range_50p_area'), np.float32),\n",
    "             \n",
    "             (('Drift time between main S1 and S2 in ns',\n",
    "                   'drift_time'), np.int64),\n",
    "            ]\n",
    "    \n",
    "    def compute_loop(self, event, peaks):\n",
    "        result = dict(n_peaks=len(peaks))\n",
    "        if not len(peaks):\n",
    "            return result\n",
    "        \n",
    "        main_s = dict()\n",
    "        for s_i in [1, 2]:\n",
    "            ss = peaks[peaks['type'] == s_i]\n",
    "            if not len(ss):\n",
    "                continue\n",
    "            main_i = result[f's{s_i}_index'] = np.argmax(ss['area'])\n",
    "            s = main_s[s_i] = ss[main_i]\n",
    "            for prop in 'area area_fraction_top range_50p_area'.split():\n",
    "                result[f's{s_i}_{prop}'] = s[prop]\n",
    "                \n",
    "        if len(main_s) == 2:\n",
    "            result['drift_time'] = main_s[2]['time'] - main_s[1]['time']\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info('event_basics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_props = EventBasics().process_and_slurp(data_dir, n_per_iter=10)\n",
    "df = pd.DataFrame.from_records(ev_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['drift_time'] / int(1e3),\n",
    "            df['s2_range_50p_area'] / int(1e3),\n",
    "            c=df['s1_area_fraction_top'],\n",
    "            vmin=0, vmax=0.25, cmap=plt.cm.jet,\n",
    "            marker='.', edgecolors='none')\n",
    "plt.colorbar(label=\"S1 area fraction top\", extend='max')\n",
    "plt.xlabel('Drift time (us)')\n",
    "plt.ylabel('S2 width (us)')\n",
    "plt.ylim(0, 4)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info('peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_plugin\n",
    "class LargestPeakArea(LoopPlugin):\n",
    "    depends_on = ('events', 'peak_basics')\n",
    "    dtype = [(('Area of largest peak in event (PE)',\n",
    "                   'largest_area'), np.float32)]\n",
    "    \n",
    "    def compute_loop(self, event, peaks):\n",
    "        x = 0\n",
    "        if len(peaks):\n",
    "            x = peaks['area'].max()\n",
    "\n",
    "        return dict(largest_area=x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(LargestPeakArea().process_and_slurp(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show we've been shown all the correct peaks\n",
    "# ps = chio.slurp(data_dir + '/peak_basics')\n",
    "# n_contained_in = np.bincount(fully_contained_in(ps, events) + 1)[1:]\n",
    "# assert np.all(ev_props['n_peaks'] == n_contained_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find stuff to investigate (old, but useful functions also below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = provider('peak_basics').process_and_slurp(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['n_channels'] >= 5\n",
    "#mask &= ~np.in1d(max_pmt, [31, 87])\n",
    "d = df[mask]\n",
    "\n",
    "plt.scatter(d['area'], \n",
    "            d['range_50p_area'],\n",
    "            c=d['area_fraction_top'], \n",
    "            s=0.1,\n",
    "            cmap=plt.cm.rainbow, vmin=0, vmax=1)\n",
    "\n",
    "plt.colorbar(label='Area fraction top')\n",
    "plt.xlabel(\"Area (pe)\")\n",
    "plt.ylabel(\"Width (50% area, ns)\")\n",
    "plt.gca().patch.set_facecolor('black')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(1, 5e6)\n",
    "plt.ylim(10, 2e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform inspection tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_i(t, subdir='records'):\n",
    "    chunk_starts = get_chunk_starts(subdir)\n",
    "    i = np.searchsorted(chunk_starts, t) - 1\n",
    "    if i < 0:\n",
    "        # TODO: handle starting exactly at the last chunk\n",
    "        raise ValueError(\"time before last chunk starts\")\n",
    "    # TODO: Assumes last chunk is infinitely long...\n",
    "    return i\n",
    "    \n",
    "def get_data(t_start, t_end, channels=None, subdir='records'):\n",
    "    \"\"\"Return all things from subdir that overlap with [t_start, t_end]\n",
    "    in channels.\n",
    "    \n",
    "    This is quite slow if you have big chunks.\n",
    "    \"\"\"\n",
    "    chunk_start = chunk_i(t_start, subdir)\n",
    "    chunk_end = chunk_i(t_end, subdir)\n",
    "    in_files = chunk_files(subdir)\n",
    "    result = []\n",
    "    for i in range(chunk_start, chunk_end + 1):\n",
    "        d = strax.load(in_files[i])\n",
    "        d = d[(t_start < d['time'] + d['length'] * d['dt']) \n",
    "              & (d['time'] < t_end)]\n",
    "        if channels is not None:\n",
    "            d = d[np.in1d(d['channel'], channels)]\n",
    "        result.append(d)\n",
    "    return np.concatenate(result)\n",
    "    \n",
    "def plot_wvs(r, t0=None, time_unit='ns', alternate_colors=False, **kwargs):\n",
    "    time_unit_str = time_unit\n",
    "    time_unit_num = int(dict(ns=1, us=1e3, ms=1e6, s=1e9)[time_unit])\n",
    "\n",
    "    t0 = r['time'][0]\n",
    "    for i, d in enumerate(r):\n",
    "        length = d['length']\n",
    "        w = d['data'][:length]\n",
    "        t = (np.arange(length, dtype=np.int64) * d['dt'] + (d['time'] - t0)) \n",
    "        if alternate_colors:\n",
    "            color = 'k' if i % 2 == 0 else 'darkslategrey'\n",
    "        else:\n",
    "            color = 'k'\n",
    "        plt.plot(t/time_unit_num, w/d['dt'], color=color, **kwargs)\n",
    "        \n",
    "    plt.xlabel(\"Time (%s)\" % time_unit_str)\n",
    "    plt.ylabel(\"Amplitude (pe/ns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to view PMT waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = strax.io_chunked.slurp_df(data_dir + '/peak_basics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = df[\n",
    "    (df['area'] > 1e4)\n",
    "    & (df['area_fraction_top'] > 0.9)\n",
    "    & (df['max_pmt'] == 87)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_data(d.time - before, d.endtime + after, subdir='peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wv(t_start, t_end, subdir='peaks', channels=None, **kwargs):\n",
    "    r = get_data(t_start, t_end, subdir=subdir, channels=channels)\n",
    "    if len(r):\n",
    "        plot_wvs(r, **kwargs)\n",
    "    else:\n",
    "        print(\"Nothing found\")\n",
    "    \n",
    "def get_wv_of(x, extend=0, **kwargs):\n",
    "    try:\n",
    "        t_end = x['endtime']\n",
    "    except KeyError:\n",
    "        t_end = x['time'] + x['dt'] * x['length']\n",
    "    get_wv(x['time'] - extend, t_end + extend,\n",
    "            **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wv_of(sd.iloc[1], extend=int(1e5), \n",
    "          channels=[87], subdir='records',\n",
    "          time_unit='us', alternate_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = get_chunk_starts('records')\n",
    "detector_time = (ts[-1] - ts[0] + np.diff(ts).mean()) / int(1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h {input_dir}/records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weirdo_is = np.where((peaks['area'] > 1e5) & (aft > 0.9))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_peak(p, t0=None, **kwargs):\n",
    "    n = p['length']\n",
    "    if t0 is None:\n",
    "        t0 = p['time']\n",
    "    plt.plot((p['time'] - t0) + np.arange(n) * p['dt'], \n",
    "             p['data'][:n] / p['dt'], \n",
    "             linestyle='steps-mid',\n",
    "             **kwargs)\n",
    "    plt.xlabel(\"Time (ns)\")\n",
    "    plt.ylabel(\"Sum waveform (PE / ns)\")\n",
    "    \n",
    "def plot_peaks(peaks):\n",
    "    t0 = peaks[0]['time']\n",
    "    for p in peaks:\n",
    "        plot_peak(p, t0=t0,\n",
    "                  label='%.1e PE, %d ns dt' % (p['area'], p['dt'], ))\n",
    "    plt.ylim(0, None)\n",
    "\n",
    "i = weirdo_is[0]\n",
    "plot_peaks(peaks[i-1:i+5])\n",
    "plt.legend(loc='best')\n",
    "#plt.yscale('symlog')\n",
    "plt.show()\n",
    "aft[i-1:i+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peaks[max_pmt[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
